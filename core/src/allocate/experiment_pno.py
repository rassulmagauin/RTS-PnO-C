import os, sys
import json
import time

import numpy as np
import pyepo
import pyepo.metric
import torch
import torch.nn as nn
import torch.optim as optim

from .data_provider import get_allocating_loader_and_dataset
import models
from models.Allocate import AllocateModel
from common.experiment import Experiment, EarlyStopping
from utils.case_logger import CaseLogger

class PnOExperiment(Experiment):
    def __init__(self, configs):
        super().__init__(configs)
        self.alpha = configs.error_rate
        self.horizon= configs.pred_len
        self._build_forecast_model()
        self._init_constraint()
        self._build_allocate_model()
        self._build_dataloaders()
        if self.configs.data_path != "exchange_rate_600s.csv":
            self._cal_constraint(self.val_loader, self.val_set)
            self._build_allocate_model()

    def _build_dataloaders(self):
        self.train_loader, self.train_set = get_allocating_loader_and_dataset(self.configs, self.allocate_model, split='train', shuffle=True)
        self.val_loader, self.val_set = get_allocating_loader_and_dataset(self.configs, self.allocate_model, split='val', shuffle=False)
        self.test_loader, self.test_set = get_allocating_loader_and_dataset(self.configs, self.allocate_model, split='test', shuffle=False)

    def _build_criterion(self):
        # FORCE SINGLE PROCESS to avoid CUDA fork errors
        num_processes = 1 
        
        if self.configs.criterion == "SPO+":
            criteria = pyepo.func.SPOPlus(self.allocate_model, processes=num_processes)
        elif self.configs.criterion == "MSE+SPO+":
            loss_spo = pyepo.func.SPOPlus(self.allocate_model, processes=num_processes)
            loss_mse = nn.MSELoss()
            criteria = lambda y_pred, y, action, value: loss_spo(y_pred, y, action, value) + self.configs.criterion_weight * loss_mse(y_pred, y)
        return criteria

    def _build_forecast_model(self):
        self.forecast_model = getattr(models, self.configs.model)(self.configs)
        if self.configs.use_multi_gpu:
            self.forecast_model = nn.DataParallel(self.forecast_model, device_ids=self.configs.gpus)
        self.forecast_model.to(self.device)
        self.model = self.forecast_model

    def _build_allocate_model(self):
        cap = getattr(self.configs, "mpc_first_step_cap", None)
        if cap is not None:
            print(f"   [Info] Building Training Solver with Cap: {cap}")
        self.allocate_model = AllocateModel(self.constraint, self.configs.uncertainty_quantile, first_step_cap=cap)

    def nonconformity(self, pred, true):
        return torch.nn.functional.l1_loss(pred, true, reduction="none")
    
    def _init_constraint(self):
        self.constraint = torch.ones(self.configs.n_vars, self.configs.pred_len) * 100000

    @torch.no_grad()
    def _cal_constraint(self, calib_loader, calib_set):
        self.forecast_model.eval()
        n_calibration = len(calib_set)
        calibration_scores = []
        for batch in calib_loader:
            batch = [tensor.to(self.device) for tensor in batch]
            batch_x, batch_y, optimal_action, optimal_value = batch
            batch_y_pred = self.forecast_model(batch_x)
            score = self.nonconformity(batch_y_pred, batch_y)
            calibration_scores.append(score)

        self.calibration_scores = torch.vstack(calibration_scores).transpose(0, 1)
        q = min((n_calibration + 1.0) * (1 - self.alpha) / n_calibration, 1)
        corrected_q = min((n_calibration + 1.0) * (1 - self.alpha / self.horizon) / n_calibration, 1)

        self.critical_calibration_scores = self.get_critical_scores(calibration_scores=self.calibration_scores, q=q)
        self.corrected_critical_calibration_scores = self.get_critical_scores(
            calibration_scores=self.calibration_scores, q=corrected_q
        )
        self.constraint = self.critical_calibration_scores

    def get_critical_scores(self, calibration_scores, q):
        return torch.tensor(
            [
                [
                    torch.quantile(position_calibration_scores, q=q)
                    for position_calibration_scores in feature_calibration_scores
                ]
                for feature_calibration_scores in calibration_scores
            ]
        ).T
    
    @torch.no_grad()
    def evaluate_forecast(self, eval_loader, criterion=None, load_best=False):
        if load_best:
            self._load_best_checkpoint()
        self.forecast_model.eval()
        eval_loss, pred, true = [], [], []
        for batch in eval_loader:
            batch = [tensor.to(self.device) for tensor in batch]
            batch_x, batch_y, action, optimal_value = batch
            batch_y_pred = self.forecast_model(batch_x)
            if criterion is not None:
                loss = criterion(batch_y_pred, batch_y)
                eval_loss.append(loss.item())
            pred.append(batch_y_pred.cpu().numpy())
            true.append(batch_y.cpu().numpy())
        
        if criterion is not None:
            eval_loss = np.mean(eval_loss)
        else:
            eval_loss = None

        pred = np.concatenate(pred)
        true = np.concatenate(true)
        eval_mse = np.mean((pred -  true) ** 2).item()
        eval_mae = np.mean(np.abs(pred - true)).item()
        eval_metrics = {'MSE': eval_mse, 'MAE': eval_mae}
        return eval_loss, eval_metrics

    @torch.no_grad()
    def _cal_regret(self, allocate_model, y_pred, y):
        optimal_cost = np.min(y)
        allocate_model.setObj(y_pred)
        sol, _ = allocate_model.solve()
        sol_cost = np.dot(sol, y)
        if allocate_model.modelSense == pyepo.EPO.MINIMIZE:
            loss = sol_cost - optimal_cost
        if allocate_model.modelSense == pyepo.EPO.MAXIMIZE:
            loss = optimal_cost - sol_cost
        return loss, sol

    @torch.no_grad()
    def evaluate_regret(self, eval_loader, scaler=None, log_cases=False):
        self.forecast_model.eval()
        loss = 0
        rel_loss = 0
        trial = 0
        logger = None
        if log_cases:
            cases_dir = os.path.join(self.exp_dir, "cases_test")
            os.makedirs(cases_dir, exist_ok=True)
            logger = CaseLogger(os.path.join(cases_dir, "pno_cases.jsonl"))

        count = 0
        for batch in eval_loader:
            batch = [tensor.to(self.device) for tensor in batch]
            batch_x, batch_y, optimal_action, optimal_value = batch
            with torch.no_grad():
                batch_y_pred = self.forecast_model(batch_x).to("cpu").detach().numpy()
                batch_y = batch_y.to("cpu").detach().numpy()
                optimal_value = optimal_value.to("cpu").detach().numpy()

            if scaler is not None:
                batch_y_pred = scaler.inverse_transform(batch_y_pred)
                batch_y = scaler.inverse_transform(batch_y)
                optimal_value = scaler.inverse_transform(optimal_value)

            for j in range(batch_y_pred.shape[0]):
                this_regret, this_alloc = self._cal_regret(self.allocate_model, batch_y_pred[j], batch_y[j])
                loss += this_regret
                min_val = np.min(batch_y[j])
                this_rel_regret = (this_regret / min_val) if min_val != 0 else 0
                rel_loss += (this_regret / np.min(batch_y[j]))

                if logger:
                    count += 1
                    logger.log({
                        "case_id": count,
                        "algo": "pno",
                        "regret": float(this_regret),
                        "rel_regret": float(this_rel_regret),
                        "alloc": this_alloc.tolist() if isinstance(this_alloc, np.ndarray) else list(this_alloc),
                        "true_prices": batch_y[j].tolist()
                    })
            trial += batch_x.shape[0]

        result = {'abs_regret': loss / trial, 'rel_regret': rel_loss / trial}
        return result
        
    @torch.no_grad()
    def evaluate(self, eval_loader, scaler, criterion=None, load_best=False, save_result=False):
        eval_regret = self.evaluate_regret(eval_loader, scaler, log_cases=save_result)
        _, eval_metrics = self.evaluate_forecast(eval_loader, criterion, load_best)
        eval_metrics['Regret'] = eval_regret['abs_regret']
        eval_metrics['Rel Regret'] = eval_regret['rel_regret']
        if save_result:
            self._save_results(eval_metrics)
        return eval_metrics

    def allocate(self):
        # 1. Build Optimizer
        optimizer, scheduler = self._build_optimizer()
        early_stopping = EarlyStopping(self.configs.patience)

        global_step = 0
        
        # 2. Build Initial Criterion
        criterion = self._build_criterion()

        for epoch in range(self.configs.train_epochs):
            self.forecast_model.train()
            train_loss = []
            epoch_start = time.time()
            for batch in self.train_loader:
                optimizer.zero_grad()
                batch = [tensor.to(self.device) for tensor in batch]
                batch_x, batch_y, optimal_action, optimal_value = batch
                batch_y_pred = self.forecast_model(batch_x)
                
                # Using CURRENT criterion (with current constraints/cap)
                loss = criterion(batch_y_pred, batch_y, optimal_action, optimal_value)

                loss.backward()
                optimizer.step()
                global_step += 1
                lr = optimizer.param_groups[0]['lr']
                self.writer.add_scalar('B.LR', lr, global_step)
                scheduler.step()
                train_loss.append(loss.item())

            train_loss = np.average(train_loss)
            print(f"Epoch: {epoch + 1} || Training Time: {time.time() - epoch_start:.2f}s")
            print(f"Epoch: {epoch + 1} || Training Loss: {train_loss:.10f}")

            # 3. Update Constraints & Model
            self._cal_constraint(self.val_loader, self.val_set)
            self._build_allocate_model()
            
            # 4. CRITICAL FIX: Rebuild Criterion so Training sees the new constraints/cap model
            criterion = self._build_criterion()

            val_start = time.time()
            val_metrics = self.evaluate(self.val_loader, self.val_set.scaler)
            val_end = time.time()
            test_metrics = self.evaluate(self.test_loader, self.test_set.scaler)

            print(f"Epoch: {epoch + 1} Val  || Time: {val_end - val_start:.2f}")
            print(f"Epoch: {epoch + 1} Val  || Regret: {val_metrics['Regret']:.8f} || Rel Regret: {val_metrics['Rel Regret']:.8f} || MSE: {val_metrics['MSE']:.4f} || MAE: {val_metrics['MAE']:.4f}")
            print(f"Epoch: {epoch + 1} Test || Regret: {test_metrics['Regret']:.8f} || Rel Regret: {test_metrics['Rel Regret']:.8f} || MSE: {test_metrics['MSE']:.4f} || MAE: {test_metrics['MAE']:.4f}")

            if self.configs.train_epochs > 50:
                early_stopping(val_metrics['Regret'])
                if early_stopping.save_model:
                    self._save_checkpoint()
                    self._save_calib_scores(self.constraint.cpu().detach(), "constraint.pt")
                if early_stopping.early_stop:
                    print("Early stopping")
                    break
            else:
                self._save_checkpoint()
                self._save_calib_scores(self.constraint.cpu().detach(), "constraint.pt")

            self.writer.add_scalar('A.Loss/a.Train', train_loss, global_step)
            self.writer.add_scalar('E.Regret/a.Val', val_metrics['Regret'], global_step)
            # ...

        self._load_best_checkpoint()
        return self.model

    def _save_results(self, metrics):
        res_path = os.path.join(self.exp_dir, 'result.json')
        with open(res_path, 'w') as fout:
            json.dump(metrics, fout, indent=4)
    
    def _save_calib_scores(self, score, name):
        score_path = os.path.join(self.exp_dir, name)
        torch.save(score, score_path)